{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAAPL\\nMSFT\\nNVDA\\nTSLA\\nAMZN\\nGOOGL\\nMETA\\nNFLX\\nAVGO\\nPYPL\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "AAPL\n",
    "MSFT\n",
    "NVDA\n",
    "TSLA\n",
    "AMZN\n",
    "GOOGL\n",
    "META\n",
    "NFLX\n",
    "AVGO\n",
    "PYPL\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for aapl saved to data/aapl.json\n",
      "Data for msft saved to data/msft.json\n",
      "Data for nvda saved to data/nvda.json\n",
      "Data for tsla saved to data/tsla.json\n",
      "Data for amzn saved to data/amzn.json\n",
      "Data for googl saved to data/googl.json\n",
      "Data for meta saved to data/meta.json\n",
      "Data for nflx saved to data/nflx.json\n",
      "Data for avgo saved to data/avgo.json\n",
      "Data for pypl saved to data/pypl.json\n"
     ]
    }
   ],
   "source": [
    "# function to fetch data from the api and save to json fie\n",
    "def fetch_ticker_data(ticker, start_date, token):\n",
    "    base_url = f\"https://api.tiingo.com/tiingo/daily/{ticker}/prices\"\n",
    "    params = {\n",
    "        \"startDate\": start_date,\n",
    "        \"token\": token\n",
    "    }\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    response = requests.get(base_url, headers=headers, params=params)\n",
    "    \n",
    "    # check for errors\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch data for {ticker}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    # save data to a json file\n",
    "    try:\n",
    "        data = response.json()\n",
    "        with open(f\"data/{ticker}.json\", \"w\") as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "        print(f\"Data for {ticker} saved to data/{ticker}.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving data for {ticker}: {e}\")\n",
    "\n",
    "# dictionary with specific start dates for each ticker\n",
    "ticker_start_dates = {\n",
    "    \"aapl\": \"1980-12-12\",\n",
    "    \"msft\": \"1986-03-13\",\n",
    "    \"nvda\": \"1999-01-22\",\n",
    "    \"tsla\": \"2010-06-29\",\n",
    "    \"amzn\": \"1997-05-15\",\n",
    "    \"googl\": \"2004-08-19\",\n",
    "    \"meta\": \"2012-05-18\",\n",
    "    \"nflx\": \"2002-05-23\",\n",
    "    \"avgo\": \"2009-08-06\",\n",
    "    \"pypl\": \"2015-07-20\"\n",
    "}\n",
    "\n",
    "# api token\n",
    "token = \"f7cb488aecfacfa7d949fe8c70c5edf9fa65c471\"\n",
    "\n",
    "# fetch data for each ticker and save it to a json file\n",
    "for ticker, start_date in ticker_start_dates.items():\n",
    "    fetch_ticker_data(ticker, start_date, token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
